{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW5_oFVd9-pY"
      },
      "source": [
        "## The second In-class-exercise (09/13/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kindly use the provided .ipynb document to write your code or respond to the questions. Avoid generating a new file.\n",
        "Execute all the cells before your final submission."
      ],
      "metadata": {
        "id": "mAzh1U0sE5I5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This in-class exercise is due tomorrow September 14, 2023 at 11:59 PM. No late submissions will be considered."
      ],
      "metadata": {
        "id": "PpgvZQdRE-HV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QBZI-je9-pZ"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWoKpYQT9-pa"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LmNR3kw9-pa"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "\n",
        "Certainly, let's consider an interesting research question related to the impact of remote work on employee productivity:\n",
        "\n",
        "**Research Question**:\n",
        "*\"What is the relationship between remote work arrangements and employee productivity, and are there specific factors that significantly influence this relationship?\"*\n",
        "\n",
        "**Data Needed**:\n",
        "To answer this question, we would need the following data:\n",
        "\n",
        "1. **Employee Data**: Information about individual employees, including their roles, job functions, work experience, and demographics (e.g., age, gender).\n",
        "\n",
        "2. **Work Arrangement Data**: Details about employees' work arrangements, including whether they work remotely, their remote work frequency (e.g., full-time, part-time), and the duration of remote work arrangements.\n",
        "\n",
        "3. **Productivity Metrics**: Quantitative measures of employee productivity, which could include performance metrics (e.g., project completion rates, sales numbers), work hours, and possibly subjective measures like self-assessed productivity.\n",
        "\n",
        "4. **Additional Factors**: Data on potential factors that could influence productivity, such as access to technology, quality of remote work setup, team communication tools, and the presence of distractions.\n",
        "\n",
        "**Data Quantity**:\n",
        "The number of data points needed would depend on the scale and scope of the research. To achieve meaningful results, it's essential to have a sufficiently large and diverse dataset. A sample size of several hundred to several thousand employees across various industries and roles would be ideal. However, the more data you have, the more robust your analysis is likely to be.\n",
        "\n",
        "**Steps for Data Collection**:\n",
        "\n",
        "1. **Employee Data**:\n",
        "   - Collect data on employees' roles, job functions, work experience, and demographics from HR records, surveys, or databases.\n",
        "   - Ensure that all data collection complies with relevant privacy regulations.\n",
        "\n",
        "2. **Work Arrangement Data**:\n",
        "   - Determine the criteria for categorizing remote work arrangements (e.g., full-time, part-time) and collect this information from HR records or surveys.\n",
        "   - Record the duration of remote work arrangements.\n",
        "\n",
        "3. **Productivity Metrics**:\n",
        "   - Collect quantitative productivity metrics specific to each employee's job role. Ensure these metrics are objective and can be consistently measured.\n",
        "   - Gather data on work hours, either through time tracking software or self-reporting.\n",
        "\n",
        "4. **Additional Factors**:\n",
        "   - Collect data on factors that could influence productivity, such as the quality of remote work setups, access to technology, and the use of team communication tools.\n",
        "   - Employee surveys and interviews can provide valuable insights into subjective factors like distractions.\n",
        "\n",
        "5. **Data Storage**:\n",
        "   - Store the collected data in a secure and structured format, such as a database or spreadsheet, ensuring that it is appropriately anonymized to protect employee privacy.\n",
        "\n",
        "6. **Data Analysis**:\n",
        "   - Analyze the data using statistical methods (e.g., regression analysis, correlation) and machine learning techniques to identify relationships and patterns.\n",
        "   - Interpret the results and draw conclusions regarding the impact of remote work on productivity and the significant influencing factors.\n",
        "\n",
        "7. **Ethical Considerations**:\n",
        "   - Ensure that all data collection and analysis processes adhere to ethical standards and legal regulations, particularly with regard to employee privacy.\n",
        "\n",
        "By following these steps, you can collect, analyze, and draw meaningful insights from the data to answer the research question regarding the impact of remote work on employee productivity.\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlxTLRNm9-pa"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QpWOgjHi9-pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa8da9b2-8d98-4628-d399-4ce83ddeae16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic data for 1000 employees generated and saved.\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create an empty DataFrame to store the data\n",
        "data = pd.DataFrame(columns=[\n",
        "    'Employee_ID',\n",
        "    'Role',\n",
        "    'Job_Function',\n",
        "    'Work_Experience',\n",
        "    'Age',\n",
        "    'Gender',\n",
        "    'Remote_Work',\n",
        "    'Remote_Work_Frequency',\n",
        "    'Remote_Work_Duration',\n",
        "    'Productivity_Score',\n",
        "    'Work_Hours',\n",
        "    'Technology_Access',\n",
        "    'Remote_Setup_Quality',\n",
        "    'Team_Communication',\n",
        "    'Distractions'\n",
        "])\n",
        "\n",
        "# Generate synthetic data for 1000 employees\n",
        "for i in range(1000):\n",
        "    data.loc[i] = [\n",
        "        i + 1,\n",
        "        np.random.choice(['Manager', 'Developer', 'Designer', 'Analyst'], p=[0.2, 0.4, 0.2, 0.2]),\n",
        "        np.random.choice(['Technical', 'Administrative', 'Sales', 'Customer Support'], p=[0.4, 0.2, 0.2, 0.2]),\n",
        "        np.random.randint(0, 30),\n",
        "        np.random.randint(22, 65),\n",
        "        np.random.choice(['Male', 'Female'], p=[0.4, 0.6]),\n",
        "        np.random.choice(['Yes', 'No'], p=[0.6, 0.4]),\n",
        "        np.random.choice(['Full-Time', 'Part-Time'], p=[0.7, 0.3]),\n",
        "        np.random.randint(0, 12),\n",
        "        np.random.randint(1, 10),\n",
        "        np.random.uniform(20, 60),\n",
        "        np.random.choice(['High', 'Medium', 'Low'], p=[0.3, 0.4, 0.3]),\n",
        "        np.random.choice(['Excellent', 'Good', 'Fair'], p=[0.4, 0.4, 0.2]),\n",
        "        np.random.choice(['High', 'Medium', 'Low'], p=[0.3, 0.4, 0.3]),\n",
        "        np.random.choice(['High', 'Medium', 'Low'], p=[0.3, 0.4, 0.3])\n",
        "    ]\n",
        "\n",
        "# Save the synthetic data to a CSV file\n",
        "data.to_csv('synthetic_employee_data.csv', index=False)\n",
        "\n",
        "print(\"Synthetic data for 1000 employees generated and saved.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px6wgvog9-pa"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2013-2023).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5rjlclf9-pb"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Function to scrape article data from Google Scholar\n",
        "def scrape_google_scholar(query, num_articles=1000, years=(2013, 2023)):\n",
        "    base_url = \"https://scholar.google.com/scholar\"\n",
        "\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Your User-Agent String\"\n",
        "    }\n",
        "\n",
        "    articles = []\n",
        "    page = 0\n",
        "\n",
        "    while len(articles) < num_articles:\n",
        "        params = {\n",
        "            \"q\": query,\n",
        "            \"hl\": \"en\",\n",
        "            \"as_sdt\": \"0,5\",\n",
        "            \"as_ylo\": years[0],\n",
        "            \"as_yhi\": years[1],\n",
        "            \"start\": page * 10\n",
        "        }\n",
        "\n",
        "        response = requests.get(base_url, params=params, headers=headers)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        results = soup.find_all(\"div\", {\"class\": \"gs_ri\"})\n",
        "\n",
        "        for result in results:\n",
        "            try:\n",
        "                title = result.find(\"h3\", {\"class\": \"gs_rt\"}).text.strip()\n",
        "                venue = result.find(\"div\", {\"class\": \"gs_a\"}).text.strip()\n",
        "                year = result.find(\"div\", {\"class\": \"gs_a\"}).text.strip().split(\" - \")[-1]\n",
        "                authors = result.find(\"div\", {\"class\": \"gs_a\"}).text.strip().split(\" - \")[0]\n",
        "                abstract = result.find(\"div\", {\"class\": \"gs_rs\"}).text.strip()\n",
        "\n",
        "                articles.append({\n",
        "                    \"Title\": title,\n",
        "                    \"Venue\": venue,\n",
        "                    \"Year\": year,\n",
        "                    \"Authors\": authors,\n",
        "                    \"Abstract\": abstract\n",
        "                })\n",
        "\n",
        "                if len(articles) >= num_articles:\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "        page += 1\n",
        "        time.sleep(1)  # Add a delay to avoid overloading the server\n",
        "\n",
        "    return articles\n",
        "\n",
        "# Scrape 1000 articles on \"information retrieval\" from Google Scholar\n",
        "articles_data = scrape_google_scholar(\"information retrieval\", num_articles=1000, years=(2013, 2023))\n",
        "\n",
        "# Create a DataFrame to store the collected data\n",
        "articles_df = pd.DataFrame(articles_data)\n",
        "\n",
        "# Save the data to a CSV file\n",
        "articles_df.to_csv('information_retrieval_articles.csv', index=False)\n",
        "\n",
        "print(\"Collected data for {} articles and saved to 'information_retrieval_articles.csv'.\".format(len(articles_df)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do either of the question-4 tasks given below."
      ],
      "metadata": {
        "id": "yCQpbJnwTxAB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT3CNj_V9-pb"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data.\n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FymVNKVi9-pb"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4 (10 points):\n",
        "\n",
        "In this task, you are required to identify and utilize online tools for web scraping data from websites without the need for coding, with a specific focus on Parsehub. The objective is to gather data and save it in formats like CSV, Excel, or any other suitable file format.\n",
        "\n",
        "You have to mention an introduction to the tool which ever you prefer to use, steps to follow for web scrapping and the final output of the data collected.\n",
        "\n",
        "Upload a document (Word or PDF File) in the same repository and you can add the link in the ipynb file."
      ],
      "metadata": {
        "id": "wOeAr9TJTBgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the link to the document here"
      ],
      "metadata": {
        "id": "N20TjXLmTG1u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}